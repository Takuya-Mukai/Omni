{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnUTObth9EXH"
   },
   "source": [
    "# 第3回講義 演習  \n",
    "\n",
    "今回は，深層モデルやそのライブラリは用いず，多層パーセプトロンを実装します．\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt7ibMdOYDDb"
   },
   "source": [
    "## 目次\n",
    "\n",
    "1. [【課題 1】多層パーセプトロンの実装と学習(XOR)](#scrollTo=GGnLlc7ACgxf)\n",
    "\n",
    "    1.1. [活性化関数とその微分](#scrollTo=Kxzqey199-33)\n",
    "    \n",
    "    1.2. [データセットの設定と重みの定義](#scrollTo=9X-jAIqoCWsp)\n",
    "    \n",
    "    1.3. [train関数とvalid関数](#scrollTo=ZcG-GIvyDYXe)\n",
    "    \n",
    "    1.4. [学習](#scrollTo=Ep9LqYJtPl_s)\n",
    "\n",
    "1. [【課題 2】多層パーセプトロンの実装と学習(MNIST)](#scrollTo=fdEpBD--P8fD)\n",
    "\n",
    "    2.1. [ソフトマックス関数](#scrollTo=UDUGHs8TfXH2)\n",
    "    \n",
    "    2.2. [データセットの設定](#scrollTo=vTArTuMYgYDk)\n",
    "    \n",
    "    2.3. [全結合層の定義](#scrollTo=UQ75UXddhar_)\n",
    "    \n",
    "    2.4. [train関数とvalid関数](#scrollTo=mK7lR2Q-lc5K)\n",
    "    \n",
    "    2.5. [学習](#scrollTo=n_O-NCslmW3p)\n",
    "\n",
    "    2.6. [Tips:実験の可視化](#scrollTo=fKEU70W8cS4i)\n",
    "\n",
    "1. [【課題 3】数値微分（勾配チェック）](#scrollTo=WA98nAv1mxWu)\n",
    "\n",
    "    3.1. [1変数の場合](#scrollTo=cTFnh6oxofw2)\n",
    "\n",
    "    3.2. [多変数の場合(MLP)](#scrollTo=wCqJgtmipLrA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DgWU0L0D9Mp-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 16:04:58.464699: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGnLlc7ACgxf"
   },
   "source": [
    "## 1.【課題 1】多層パーセプトロンの実装と学習(XOR)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kxzqey199-33"
   },
   "source": [
    "### 1.1. 活性化関数とその微分\n",
    "まずは活性化関数の定義と，勾配の計算に利用する導関数を定義していきます．ここではシグモイド関数，ReLU関数，tanh関数を実装していきます．\n",
    "\n",
    "シグモイド関数は二値分類の出力層，ReLU関数とtanh関数は隠れ層の活性化関数として用いられることが多いですが，近年では勾配消失問題の対策としてReLU関数を利用するのが一般的です．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxl16kJQkLEX"
   },
   "source": [
    "**シグモイド関数**\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(x) = \\frac{1}{1+\\text{exp}(-x)} \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma'(x) = \\sigma(x)(1-\\sigma(x)) \\tag{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0QPWWfCj-v_J"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # 単純な実装\n",
    "    # return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # expのoverflow対策を施した実装\n",
    "    # x >=0 のとき sigmoid(x) = 1 / (1 + exp(-x))\n",
    "    # x < 0 のとき sigmoid(x) = exp(x) / (1 + exp(x))\n",
    "    return np.exp(np.minimum(x, 0)) / (1 + np.exp(- np.abs(x)))\n",
    "\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BxK6w5L_iGH"
   },
   "source": [
    "**ReLU関数**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{ReLU}(x) = \\text{max}(0, x) \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{ReLU}'(x) =  \\begin{cases}\n",
    "    1 \\quad \\text{if} \\quad x > 0 \\tag{4} \\\\\n",
    "    0 \\quad \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Pxa4PUmbBq3O"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def deriv_relu(x):\n",
    "    return (x > 0).astype(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if9Fmb3UByDO"
   },
   "source": [
    "**tanh関数**\n",
    "\\begin{equation}\n",
    "    \\text{tanh}(x) = \\frac{\\text{exp}(2x)-1}{\\text{exp}(2x)+1} \\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{tanh}'(x) = 1 - \\text{tanh}^2(x) \\tag{6}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y3MBPh5rCPrH"
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def deriv_tanh(x):\n",
    "    return 1 - tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9X-jAIqoCWsp"
   },
   "source": [
    "### 1.2. データセットの設定と重みの定義  \n",
    "次にMLPを学習するためのデータセットと，パラメータの初期化を行います．\n",
    "\n",
    "まずはデータセットを作成します．\n",
    "\n",
    "データセットは非線形問題として知られるXOR問題を用います．講義でも扱いましたが，XOR問題は2つの入力$(x_1, x_2), \\quad x_1, x_2 \\in \\{0, 1\\}$を与え，2つの値が同じときは0，異なるときは1を割り当てます．これは二次元空間に描画した時に0に割り当てられる点と1に割り当てられる点を1つの直線で分類することができないため，非線形問題となっています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1742277985945,
     "user": {
      "displayName": "Ko Emiri",
      "userId": "00150941330942805838"
     },
     "user_tz": -540
    },
    "id": "7AX0WH1j6x6f",
    "outputId": "732289ca-5a78-43d2-cf68-0eb9d0bd47b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# XORデータセット\n",
    "x_train_xor = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
    "t_train_xor = np.array([[1], [1], [0], [0]])  # 正解ラベルをtとする\n",
    "x_valid_xor, t_valid_xor = x_train_xor, t_train_xor\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hlines([0], xmin=-1, xmax=2, color=\"black\", alpha=0.7)\n",
    "plt.vlines([0], ymin=-1, ymax=2, color=\"black\", alpha=0.7)\n",
    "plt.scatter(x_train_xor[0:2, 0], x_train_xor[0:2, 1], color=\"red\", label=\"1\")\n",
    "plt.scatter(x_train_xor[2:, 0], x_train_xor[2:, 1], color=\"blue\", label=\"0\")\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\")\n",
    "plt.xlim([-0.5, 1.5])\n",
    "plt.ylim([-0.5, 1.5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO_FNY4N7O0v"
   },
   "source": [
    "次にパラメータを初期化します．重みは一様分布からのサンプリング，バイアスは0で初期化を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HrTd126iCcRv"
   },
   "outputs": [],
   "source": [
    "# 重み（入力層の次元数: 2，隠れ層の次元数: 8，出力層の次元数: 1）\n",
    "W1 = np.random.uniform(low=-0.08, high=0.08, size=(2, 8)).astype(\"float64\")\n",
    "b1 = np.zeros(8).astype(\"float64\")\n",
    "W2 = np.random.uniform(low=-0.08, high=0.08, size=(8, 1)).astype(\"float64\")\n",
    "b2 = np.zeros(1).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcG-GIvyDYXe"
   },
   "source": [
    "### 1.3. train関数とvalid関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmpRvsU_DkVI"
   },
   "source": [
    "隠れ層と出力層の2層からなるMLPを実装していきます．\n",
    "\n",
    "なお今回は，予測ラベルを$y$，正解ラベルを$t$，学習率を$ε$\n",
    "とします（今後の演習でもこの表記を使用することがあります）．\n",
    "\n",
    "**目的関数**\n",
    "\n",
    "負の対数尤度（2クラス交差エントロピー）\n",
    "\\begin{equation}\n",
    "E(\\mathbf{x}, \\mathbf{t}) = - \\frac{1}{N} \\sum^N_{i=1}\\left[ \\mathbf{t}_i \\log{\\mathbf{y}_i} + (1 - \\mathbf{t}_i) \\log{(1 - \\mathbf{y_i})}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "**順伝播**\n",
    "\\begin{align}\n",
    "\\mathbf{u}^{1} &= (\\mathbf{W}^{1})^{T} \\mathbf{x} + \\mathbf{b}^{1} \\tag{隠れ層} \\\\\n",
    "\\mathbf{h}^{1} &= \\text{ReLU}(\\mathbf{u}^{1}) \\tag{隠れ層} \\\\\n",
    "\\mathbf{u}^{2} &= (\\mathbf{W}^{2})^{T} \\mathbf{h}^{1} + \\mathbf{b}^{2} \\tag{出力層} \\\\\n",
    "\\mathbf{y} &= \\sigma(\\mathbf{u}^{2}) \\tag{出力層}\n",
    "\\end{align}\n",
    "\n",
    "**逆伝播**\n",
    "\\begin{align}\n",
    "\\delta^{2} &= \\mathbf{y} - \\mathbf{t} \\tag{出力層} \\\\\n",
    "\\delta^{1} &= \\text{ReLU}'(\\mathbf{u}^{1}) \\odot ((\\mathbf{W}^{2})^{T} \\delta^{2}) \\tag{隠れ層}\n",
    "\\end{align}\n",
    "\n",
    "**勾配の計算**\n",
    "\\begin{align}\n",
    "\\nabla_{\\mathbf{W}^{1}}E &= \\frac{1}{N}\\delta^{1}\\mathbf{x}^T \\tag{隠れ層} \\\\\n",
    "\\nabla_{\\mathbf{b}^{1}}E &= \\frac{1}{N}\\delta^{1}\\mathbb{1}_N \\tag{隠れ層} \\\\\n",
    "\\nabla_{\\mathbf{W}^{2}}E &= \\frac{1}{N}\\delta^{2}(\\mathbf{h}^{1})^{T} \\tag{出力層} \\\\\n",
    "\\nabla_{\\mathbf{b}^{2}}E &= \\frac{1}{N}\\delta^{2}\\mathbb{1}_N \\tag{出力層}\n",
    "\\end{align}\n",
    "\n",
    "**重みの更新**\n",
    "\\begin{align}\n",
    "\\mathbf{W}^{1} \\leftarrow \\mathbf{W}^{1} - \\epsilon \\nabla_{\\mathbf{W}^{1}} E \\tag{隠れ層} \\\\\n",
    "\\mathbf{b}^{1} \\leftarrow \\mathbf{b}^{1} - \\epsilon \\nabla_{\\mathbf{b}^{1}} E \\tag{隠れ層} \\\\\n",
    "\\mathbf{W}^{2} \\leftarrow \\mathbf{W}^{2} - \\epsilon \\nabla_{\\mathbf{W}^{2}} E \\tag{出力層} \\\\\n",
    "\\mathbf{b}^{2} \\leftarrow \\mathbf{b}^{2} - \\epsilon \\nabla_{\\mathbf{b}^{2}} E \\tag{出力層}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JvI5FXhbPOF0"
   },
   "outputs": [],
   "source": [
    "# logの中身が0になることを防ぐ\n",
    "def np_log(x):\n",
    "    return np.log(np.clip(x, 1e-10, 1e+10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rOYS37oDPVEM"
   },
   "outputs": [],
   "source": [
    "def train_xor(x, t, eps):\n",
    "    \"\"\"\n",
    "    :param x: np.ndarray, 入力データ, (batch_size, 入力層の次元数)\n",
    "    :param t: np.ndarray, 教師ラベル, (batch_size, 出力層の次元数)\n",
    "    :param eps: float, 学習率\n",
    "    \"\"\"\n",
    "    global W1, b1, W2, b2\n",
    "\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    # 順伝播\n",
    "    u1 = np.matmul(x, W1) + b1  # (batch_size, 隠れ層の次元数)\n",
    "    h1 = relu(u1)\n",
    "\n",
    "    u2 = np.matmul(h1, W2) + b2  # (batch_size, 出力層の次元数)\n",
    "    y = sigmoid(u2)\n",
    "\n",
    "    # 誤差の計算\n",
    "    cost = (- t * np_log(y) - (1 - t) * np_log(1 - y)).mean()\n",
    "\n",
    "    # 逆伝播\n",
    "    delta_2 = y - t   # WRITE ME # (batch_size, 出力層の次元数)\n",
    "    delta_1 = deriv_relu(u1) * np.matmul(delta_2, W2.T)   # WRITE ME # (batch_size, 隠れ層の次元数)\n",
    "\n",
    "    # 勾配の計算\n",
    "    dW1 = np.matmul(x.T, delta_1) / batch_size   # WRITE ME # (入力層の次元数, 隠れ層の次元数)\n",
    "    db1 = np.matmul(np.ones(batch_size), delta_1) / batch_size   # WRITE ME # (隠れ層の次元数,)\n",
    "\n",
    "    dW2 = np.matmul(h1.T, delta_2) / batch_size   # WRITE ME # (隠れ層の次元数, 出力層の次元数)\n",
    "    db2 = np.matmul(np.ones(batch_size), delta_2) / batch_size   # WRITE ME # (出力層の次元数,)\n",
    "\n",
    "    # パラメータの更新\n",
    "    W1 -= eps * dW1 # WRITE ME\n",
    "    b1 -= eps * db1 # WRITE ME\n",
    "\n",
    "    W2 -= eps * dW2 # WRITE ME\n",
    "    b2 -= eps * db2 # WRITE ME\n",
    "\n",
    "    return cost\n",
    "\n",
    "def valid_xor(x, t):\n",
    "    global W1, b1, W2, b2\n",
    "\n",
    "    # 順伝播\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    h1 = relu(u1)\n",
    "\n",
    "    u2 = np.matmul(h1, W2) + b2\n",
    "    y = sigmoid(u2)\n",
    "\n",
    "    # 誤差の計算\n",
    "    cost = (- t * np_log(y) - (1 - t) * np_log(1 - y)).mean() # WRITE ME\n",
    "\n",
    "    return cost, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep9LqYJtPl_s"
   },
   "source": [
    "### 1.4. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1703,
     "status": "ok",
     "timestamp": 1742278006257,
     "user": {
      "displayName": "Ko Emiri",
      "userId": "00150941330942805838"
     },
     "user_tz": -540
    },
    "id": "FeIR5sbZPoh6",
    "outputId": "e5974e1c-2f51-46ac-ddbc-9061026b5fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99905291]\n",
      " [0.99902943]\n",
      " [0.0082319 ]\n",
      " [0.00103143]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3000):\n",
    "    # オンライン学習\n",
    "    for x, t in zip(x_train_xor, t_train_xor):\n",
    "        cost = train_xor(x[None, :], t[None, :], eps=0.05)\n",
    "\n",
    "cost, y_pred = valid_xor(x_valid_xor, t_valid_xor)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdEpBD--P8fD"
   },
   "source": [
    "## 2.【課題 2】多層パーセプトロンの実装と学習(MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDUGHs8TfXH2"
   },
   "source": [
    "### 2.1. ソフトマックス関数\n",
    "ソフトマックス関数は多クラス分類の出力層で用いられる活性化関数です．こちらも勾配の計算に利用するために導関数も実装していきます．  \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{softmax}(\\mathbf{x})_k = \\frac{\\text{exp}(\\mathbf{x}_k)}{\\sum^K_{k'=1} \\text{exp}(\\mathbf{x}_{k'})} \\quad \\quad \\text{for} \\quad k=1, \\dots K\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{softmax}'(\\mathbf{x})_k = \\text{softmax}(\\mathbf{x})_k (1 - \\text{softmax}(\\mathbf{x}))_k\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9cubfAAegHIm"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x -= x.max(axis=1, keepdims=True)  # オーバーフローを避ける\n",
    "    x_exp = np.exp(x)\n",
    "    return x_exp / np.sum(x_exp, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def deriv_softmax(x):\n",
    "    return softmax(x) * (1 - softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTArTuMYgYDk"
   },
   "source": [
    "### 2.2. データセットの設定\n",
    "次にデータセットを作成します．ここでは第2回の演習でも利用したMNISTデータセットを用います．データセット・データの前処理に関する説明については第2回の演習をご参考ください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1742278019526,
     "user": {
      "displayName": "Ko Emiri",
      "userId": "00150941330942805838"
     },
     "user_tz": -540
    },
    "id": "CLJBpp9EgdIP",
    "outputId": "2de20826-ba6e-455c-d1ea-c62cd8db8d5e"
   },
   "outputs": [],
   "source": [
    "(x_mnist_1, t_mnist_1), (x_mnist_2, t_mnist_2) = mnist.load_data()\n",
    "\n",
    "x_mnist = np.r_[x_mnist_1, x_mnist_2]\n",
    "t_mnist = np.r_[t_mnist_1, t_mnist_2]\n",
    "\n",
    "x_mnist = x_mnist.astype(\"float64\") / 255.  # 値を[0, 1]に正規化する\n",
    "t_mnist = np.eye(N=10)[t_mnist.astype(\"int32\").flatten()]  # one-hotベクトルにする\n",
    "\n",
    "x_mnist = x_mnist.reshape(x_mnist.shape[0], -1)  # 1次元に変換\n",
    "\n",
    "# train data: 5000, valid data: 10000, test data: 10000にする\n",
    "x_train_mnist, x_test_mnist, t_train_mnist, t_test_mnist =\\\n",
    "    train_test_split(x_mnist, t_mnist, test_size=10000)\n",
    "x_train_mnist, x_valid_mnist, t_train_mnist, t_valid_mnist =\\\n",
    "    train_test_split(x_train_mnist, t_train_mnist, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ75UXddhar_"
   },
   "source": [
    "### 2.3. 全結合層の定義  \n",
    "\n",
    "多層のMLPを実装できるように，全結合層をクラスとして定義します．\n",
    "\n",
    "順伝播，逆伝播，勾配の計算をそれぞれ関数として実装します．\n",
    "\n",
    "数式は以下のようになります．  \n",
    "\n",
    "**順伝播**(`__call__`)\n",
    "\\begin{align}\n",
    "\\mathbf{u}^{l} &= (\\mathbf{W}^{l})^{T}\\mathbf{h}^{l-1} + \\mathbf{b}^{l}  \\\\\n",
    "\\mathbf{h}^{l} &= \\text{function}(\\mathbf{u}^{l})\n",
    "\\end{align}\n",
    "\n",
    "**逆伝播**(`b_prop`)\n",
    "\\begin{equation}\n",
    "\\delta^{l} = \\text{function}'(\\mathbf{u}^{l}) \\odot ((\\mathbf{W}^{l+1})^{T} \\delta^{l+1})\n",
    "\\end{equation}\n",
    "\n",
    "**勾配の計算**(`compute_grad`)\n",
    "\\begin{align}\n",
    "\\nabla_{\\mathbf{W}^{l}}E &= \\frac{1}{N}\\delta^{l}(\\mathbf{h}^{l-1})^{T} \\\\\n",
    "\\nabla_{\\mathbf{b}^{l}}E &= \\frac{1}{N}\\delta^{l}\\mathbb{1}_N\n",
    "\\end{align}\n",
    "\n",
    "`__call__`は，インスタンスを関数のように呼び出すための特殊メソッドです．\n",
    "```python\n",
    "Class A:\n",
    "  def __init__(self):\n",
    "    ...\n",
    "  def __call__(self):\n",
    "    print('Hello World.')\n",
    "\n",
    "a = A()\n",
    "a()  # __call__が呼び出される\n",
    "# Hello world.\n",
    "```\n",
    "\n",
    "`get_params`，`set_params`，`get_grads`はそれぞれ重み，勾配をベクトルで受け渡す関数です．課題3の勾配チェックの際に使用します．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yuAPucgki9wF"
   },
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function, deriv_function):\n",
    "        self.W = np.random.uniform(low=-0.08, high=0.08,\n",
    "                                   size=(in_dim, out_dim)).astype(\"float64\")\n",
    "        self.b = np.zeros(out_dim).astype(\"float64\")\n",
    "        self.function = function\n",
    "        self.deriv_function = deriv_function\n",
    "\n",
    "        self.x = None\n",
    "        self.u = None\n",
    "\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "        self.params_idxs = np.cumsum([self.W.size, self.b.size])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        順伝播処理を行うメソッド．\n",
    "        x: (batch_size, in_dim_{j})\n",
    "        h: (batch_size, out_dim_{j})\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.u = np.matmul(self.x, self.W) + self.b\n",
    "        h = self.function(self.u)\n",
    "        return h\n",
    "\n",
    "    def b_prop(self, delta, W):\n",
    "        \"\"\"\n",
    "        誤差逆伝播を行うメソッド．\n",
    "        delta (=delta_{j+1}): (batch_size, out_dim_{j+1})\n",
    "        W (=W_{j+1}): (out_dim_{j}, out_dim_{j+1})\n",
    "        self.delta (=delta_{j}): (batch_size, out_dim_{j})\n",
    "        \"\"\"\n",
    "        self.delta = self.deriv_function(self.u) * np.matmul(delta, W.T) # WRITE ME\n",
    "        return self.delta\n",
    "\n",
    "    def compute_grad(self):\n",
    "        \"\"\"\n",
    "        勾配を計算するメソッド．\n",
    "        self.x: (batch_size, in_dim_{j})\n",
    "        self.delta: (batch_size, out_dim_{j})\n",
    "        self.dW: (in_dim_{j}, out_dim_{j})\n",
    "        self.db: (out_dim_{j})\n",
    "        \"\"\"\n",
    "        batch_size = self.delta.shape[0]\n",
    "\n",
    "        self.dW = np.matmul(self.x.T, self.delta) / batch_size # WRITE ME\n",
    "        self.db = np.matmul(np.ones(batch_size), self.delta) / batch_size # WRITE ME\n",
    "\n",
    "    def get_params(self):\n",
    "        return np.concatenate([self.W.ravel(), self.b], axis=0)\n",
    "\n",
    "    def set_params(self, params):\n",
    "        \"\"\"\n",
    "        params: List[np.ndarray, np.ndarray]\n",
    "            1つ目の要素が重みW: (in_dim, out_dim)，2つ目の要素がバイアス: (out_dim,)\n",
    "        \"\"\"\n",
    "        _W, _b = np.split(params, self.params_idxs)[:-1]\n",
    "        self.W = _W.reshape(self.W.shape)\n",
    "        self.b = _b\n",
    "\n",
    "    def get_grads(self):\n",
    "        return np.concatenate([self.dW.ravel(), self.db], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kpeZlEGCaTF"
   },
   "source": [
    "このDenseクラスを用いてモデル全体をModelクラスとして実装します．今後利用する深層学習ライブラリのPyTorchでも似たようなモデルの定義をするので今のうちに慣れておきましょう．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aqt5BqilCo1W"
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, hidden_dims, activation_functions, deriv_functions):\n",
    "        \"\"\"\n",
    "        :param hiden_dims: List[int]，各層のノード数を格納したリスト．\n",
    "        :params activation_functions: List, 各層で用いる活性化関数を格納したリスト．\n",
    "        :params derive_functions: List，各層で用いる活性化関数の導関数を格納したリスト．\n",
    "        \"\"\"\n",
    "        # 各層をリストに格納していく\n",
    "        self.layers = []\n",
    "        for i in range(len(hidden_dims)-2):  # 出力層以外は同じ構造\n",
    "            self.layers.append(Dense(hidden_dims[i], hidden_dims[i+1],\n",
    "                                     activation_functions[i], deriv_functions[i]))\n",
    "        self.layers.append(Dense(hidden_dims[-2], hidden_dims[-1],\n",
    "                                 activation_functions[-1], deriv_functions[-1]))  # 出力層を追加\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"順伝播処理を行うメソッド\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, delta):\n",
    "        \"\"\"誤差逆伝播，勾配計算を行うメソッド\"\"\"\n",
    "        batch_size = delta.shape[0]\n",
    "\n",
    "        for i, layer in enumerate(self.layers[::-1]):\n",
    "            if i == 0:  # 出力層の場合\n",
    "                layer.delta = delta  # y - t\n",
    "                layer.compute_grad()\n",
    "            else:  # 出力層以外の場合\n",
    "                delta = layer.b_prop(delta, W)  # 逆伝播\n",
    "                layer.compute_grad()  # 勾配の計算\n",
    "\n",
    "            W = layer.W\n",
    "\n",
    "    def update(self, eps=0.01):\n",
    "        \"\"\"パラメータの更新を行うメソッド\"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.W -= eps * layer.dW\n",
    "            layer.b -= eps * layer.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Izjg7ZSEEyoi"
   },
   "source": [
    "実際にモデルを利用するときはこのクラスのインスタンスを作成します．本課題では3層のMLPを用います．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m0VnNqrzE7Iw"
   },
   "outputs": [],
   "source": [
    "model = Model(hidden_dims=[784, 100, 100, 10],\n",
    "              activation_functions=[relu, relu, softmax],\n",
    "              deriv_functions=[deriv_relu, deriv_relu, deriv_softmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FjIR6qZIL1F"
   },
   "source": [
    "課題1ではデータを1つずつ渡すオンライン学習を用いましたが，ここではミニバッチ学習を用います．そのためにデータセットをミニバッチに分割する関数を定義します．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pwgtWxdCIMpq"
   },
   "outputs": [],
   "source": [
    "def create_batch(data, batch_size):\n",
    "    \"\"\"\n",
    "    :param data: np.ndarray，入力データ\n",
    "    :param batch_size: int，バッチサイズ\n",
    "    \"\"\"\n",
    "    num_batches, mod = divmod(data.shape[0], batch_size)\n",
    "    batched_data = np.split(data[: batch_size * num_batches], num_batches)\n",
    "    if mod:\n",
    "        batched_data.append(data[batch_size * num_batches:])\n",
    "\n",
    "    return batched_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK7lR2Q-lc5K"
   },
   "source": [
    "### 2.4. train関数とvalid関数\n",
    "\n",
    "**誤差関数**  \n",
    "\n",
    "負の対数尤度（多クラス交差エントロピー）\n",
    "\\begin{equation}\n",
    "E(\\mathbf{x}, \\mathbf{t}) = - \\frac{1}{N} \\sum^N_{i=1} \\sum^K_{k=1}\\mathbf{t}_{i, k} \\log{\\mathbf{y}_{i, k}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWNxa_1SJoBJ"
   },
   "source": [
    "上記の損失関数と，先に定義したModelクラスのインスタンスを用いて，モデルを訓練するための関数を定義します．この関数では1エポック分の訓練を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Oi_r6wsBl2gI"
   },
   "outputs": [],
   "source": [
    "def train_mst(model, x, t, eps=0.01):\n",
    "    # 順伝播\n",
    "    y = model(x)\n",
    "\n",
    "    # 誤差の計算\n",
    "    cost = (-t * np_log(y)).sum(axis=1).mean()\n",
    "\n",
    "    # 逆伝播\n",
    "    delta = y - t\n",
    "    model.backward(delta)\n",
    "\n",
    "    # パラメータの更新\n",
    "    model.update(eps)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-5n5Jg5JyNx"
   },
   "source": [
    "同様に訓練したモデルを評価するための関数を定義します．関数の中身は訓練とほとんど変わりませんが，評価時には誤差逆伝播による勾配の計算と，パラメータの更新が不要になります．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JfiV2dfPmHPI"
   },
   "outputs": [],
   "source": [
    "def valid_mst(model, x, t):\n",
    "    # 順伝播\n",
    "    y = model(x)\n",
    "\n",
    "    # 誤差の計算\n",
    "    cost = (-t * np_log(y)).sum(axis=1).mean()\n",
    "\n",
    "    return cost, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_O-NCslmW3p"
   },
   "source": [
    "### 2.5. 学習  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32882,
     "status": "ok",
     "timestamp": 1742278068342,
     "user": {
      "displayName": "Ko Emiri",
      "userId": "00150941330942805838"
     },
     "user_tz": -540
    },
    "id": "WZdTe6oJmYT1",
    "outputId": "b87811b0-8a06-421f-d69e-dd024e7ddc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 Valid Cost: 0.351 Valid Accuracy: 0.896\n",
      "EPOCH: 2 Valid Cost: 0.257 Valid Accuracy: 0.927\n",
      "EPOCH: 3 Valid Cost: 0.220 Valid Accuracy: 0.936\n",
      "EPOCH: 4 Valid Cost: 0.177 Valid Accuracy: 0.947\n",
      "EPOCH: 5 Valid Cost: 0.150 Valid Accuracy: 0.954\n",
      "EPOCH: 6 Valid Cost: 0.139 Valid Accuracy: 0.958\n",
      "EPOCH: 7 Valid Cost: 0.124 Valid Accuracy: 0.963\n",
      "EPOCH: 8 Valid Cost: 0.111 Valid Accuracy: 0.966\n",
      "EPOCH: 9 Valid Cost: 0.105 Valid Accuracy: 0.967\n",
      "EPOCH: 10 Valid Cost: 0.102 Valid Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "# バッチサイズを指定\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(10):\n",
    "    x_train_mnist, t_train_mnist = shuffle(x_train_mnist, t_train_mnist)\n",
    "    x_train_batch, t_train_batch = \\\n",
    "        create_batch(x_train_mnist, batch_size), create_batch(t_train_mnist, batch_size)\n",
    "    # ミニバッチ学習\n",
    "    for x, t in zip(x_train_batch, t_train_batch):\n",
    "        cost = train_mst(model, x, t, eps=0.1)\n",
    "\n",
    "    cost, y_pred = valid_mst(model, x_valid_mnist, t_valid_mnist)\n",
    "    accuracy = accuracy_score(t_valid_mnist.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    print(f\"EPOCH: {epoch+1} Valid Cost: {cost:.3f} Valid Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKEU70W8cS4i"
   },
   "source": [
    "### 2.6.Tips:実験の可視化\n",
    "\n",
    "通常，lossやaccuracyなどのログは，数値だけで追うのはわかりにくいため，グラフで可視化して確認します．\n",
    "\n",
    "その際によく使われるツールとして，[Weights & Biases](https://wandb.ai/site/ja/)と[Tensorboard](https://www.tensorflow.org/tensorboard?hl=ja)が挙げられます．\n",
    "\n",
    "\n",
    "- Weights & Biases: クラウドベースの実験管理ツールで，非常に多機能です．可視化だけでなく，複数の実験の比較やハイパーパラメータの自動チューニング，モデルのチェックポイント保存なども可能です．利用するにはアカウント登録が必要です．\n",
    "- Tensorboard: TensorFlow公式の可視化ツールで，ローカル環境で簡単に使うことができます．\n",
    "\n",
    "宿題や最終課題に取り組む際に積極的に活用してみてください．\n",
    "\n",
    "Google Colabでの使い方は下記を参照してください．\n",
    "\n",
    "- [Weights & Biasesのチュートリアル](https://docs.wandb.ai/ja/tutorials)\n",
    "- [Tensorboardのチュートリアル（TensorFlow）](https://www.tensorflow.org/tensorboard/get_started?hl=ja)\n",
    "- [TensorboardをPytorchで使う方法](https://qiita.com/go50/items/ae5f979b9bb36bfbb6be)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA98nAv1mxWu"
   },
   "source": [
    "## 3.【課題 3】数値微分（勾配チェック）  \n",
    "\n",
    "誤差逆伝播法による勾配の計算は少し複雑なため，実装にバグが入りがちです．\n",
    "\n",
    "実装が簡単な数値微分と結果を比較することで，逆伝播の実装が正しいかを確認してみましょう．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTFnh6oxofw2"
   },
   "source": [
    "### 3.1. 1変数の場合\n",
    "\n",
    "まず簡単な2次関数に対して数値微分を行ってみましょう．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jZm8yb1UomkR"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "def deriv_f(x):\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSbMYmfyoqKp"
   },
   "source": [
    "1変数の場合の数値微分の式は以下のようになります．  \n",
    "\n",
    "\\begin{equation}\n",
    "f'(x) = \\underset{h \\rightarrow 0}{\\text{lim}} \\frac{f(x + h) - f(x - h)}{2h}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742278074356,
     "user": {
      "displayName": "Ko Emiri",
      "userId": "00150941330942805838"
     },
     "user_tz": -540
    },
    "id": "wv9JGSOKpAXA",
    "outputId": "7842523b-e94a-4b4c-e4bc-385ac1961621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 4.000000000026205\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-5\n",
    "x = 2.0\n",
    "\n",
    "grad_auto = deriv_f(x)\n",
    "grad_num = (f(x + eps) - f(x - eps)) / (2 * eps)\n",
    "\n",
    "print(grad_auto, grad_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCqJgtmipLrA"
   },
   "source": [
    "### 3.2. 多変数の場合(MLP)\n",
    "次に課題2で定義したMLPに対して数値微分の計算を行い，誤差逆伝播による勾配(`dW`, `db`)の計算が間違っていないかを確認してみましょう．\n",
    "\n",
    "多変数(MLP)の場合の数値微分の式は次のようになります．ある1つの変数$\\theta_m$のみを$h$だけ動かした場合を考えます．  \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial E}{\\partial \\theta_m} = \\underset{h \\rightarrow 0}{\\text{lim}}\\frac{E(\\theta_1, \\theta_2, \\dots , \\theta_m + h, \\dots , \\theta_M) - E(\\theta_1, \\theta_2, \\dots , \\theta_m - h, \\dots , \\theta_M)}{2h}\n",
    "\\end{equation}\n",
    "\n",
    "実装では，変数全体のサイズのゼロベクトルを用意し，$m$番目の要素のみ$h$だけずらされたベクトルを作り，それに対応する誤差を計算し，そこから上の式に従って最終的な微分の値を求めていきます．  \n",
    "\n",
    "まず各層ごとの重みをベクトルで取得しリストで保存していく関数を実装していきます．  \n",
    "\n",
    "MLPの各レイヤーから重みをベクトルで取得するために，先ほど`Dense`クラスで定義した`set_params`，`get_params`を使用します．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "U0lpoIlsqJfw"
   },
   "outputs": [],
   "source": [
    "def get_params(layers):\n",
    "    params_all = []\n",
    "    for layer in layers:\n",
    "        params = layer.get_params()\n",
    "        params_all.append(params)\n",
    "\n",
    "    return params_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nehSAkCtqRBA"
   },
   "outputs": [],
   "source": [
    "def set_params(laeyrs, params_all):\n",
    "    for layer, params in zip(model.layers, params_all):\n",
    "        layer.set_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LT1fV2aSqVx4"
   },
   "outputs": [],
   "source": [
    "def compute_cost(x, t):\n",
    "    # 順伝播\n",
    "    y = model(x)\n",
    "\n",
    "    # 誤差の計算\n",
    "    cost = (-t * np_log(y)).sum(axis=1).mean()\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtc0XoQaqhyR"
   },
   "source": [
    "#### 3.2.1. 数値微分\n",
    "\n",
    "勾配の計算に使用するデータを用意します．勾配チェックの際はどれだけ精度よく近似できているかを見たいので，`float64`を使いましょう．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GVYwUiUvqwww"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "x = x_train_mnist[:batch_size].astype(\"float64\")\n",
    "t = t_train_mnist[:batch_size].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "D4TvumnLq20Z"
   },
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "\n",
    "params_all = get_params(model.layers)\n",
    "grads_all_num = []\n",
    "\n",
    "# レイヤーごとに勾配を計算\n",
    "for layer, params in zip(model.layers, params_all):\n",
    "    shift = np.zeros_like(params)\n",
    "    grads_num = np.zeros_like(params)\n",
    "\n",
    "    # レイヤー内のM個のパラメータに対してそれぞれ微分を計算する\n",
    "    for m in range(len(params)):\n",
    "        shift[m] = eps  # m番目のパラメータのみeps分ずらす [0, 0, ..., 0, eps, 0, ..., 0]\n",
    "\n",
    "        params_right = params + shift\n",
    "        layer.set_params(params_right)\n",
    "        cost_right = compute_cost(x, t)  # L(x; ..., \\theta_m + eps, ...)\n",
    "\n",
    "        params_left = params - shift\n",
    "        layer.set_params(params_left)\n",
    "        cost_left = compute_cost(x, t)  # L(x; ..., \\theta_m - eps, ...)\n",
    "\n",
    "        grads_num[m] = (cost_right - cost_left) / (2 * eps)  # 微分の計算\n",
    "\n",
    "        layer.set_params(params)\n",
    "        shift[m] = 0\n",
    "\n",
    "    grads_all_num.append(grads_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njAOv63or0pI"
   },
   "source": [
    "#### 3.2.2. 誤差逆伝播法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EHEBk04asHeh"
   },
   "outputs": [],
   "source": [
    "def get_grads(layers):\n",
    "    grads_all = []\n",
    "    for layer in layers:\n",
    "        grads = layer.get_grads()\n",
    "        grads_all.append(grads)\n",
    "\n",
    "    return grads_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "sSiADsqesORg"
   },
   "outputs": [],
   "source": [
    "# 順伝播\n",
    "y = model(x)\n",
    "\n",
    "# 逆伝播\n",
    "delta = y - t\n",
    "model.backward(delta)\n",
    "\n",
    "# 勾配を計算\n",
    "grads_all_bprop = get_grads(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF2AUFdtsW4g"
   },
   "source": [
    "#### 3.2.3. 比較（勾配チェック）\n",
    "\n",
    "誤差逆伝播法で計算した勾配と数値微分による勾配の差を，ノルムで正規化したrelative differenceで測ります．経験的にはその差がおおよそ1e-7以下であれば実装にバグはないと安心していいでしょう．\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{diff} = \\frac{||\\text{grad}_{\\text{bprop}} - \\text{grad}_{\\text{num}}||_2}{||\\text{grad}_{\\text{bprop}}||_2 + ||\\text{grad}_{\\text{num}}||_2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Reference: Improving Deep Neural Networks: Gradient checking https://www.coursera.org/lecture/deep-neural-network/gradient-checking-htA0l (2018年10月17日閲覧)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742278291442,
     "user": {
      "displayName": "Ko Emiri",
      "userId": "00150941330942805838"
     },
     "user_tz": -540
    },
    "id": "j5cbNK-xtKxx",
    "outputId": "199a97ce-b014-4963-bbad-0bdbe657c5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients' difference (layer 1: 1.4708231445415517e-10)\n",
      "Gradients' difference (layer 2: 6.729642479911889e-11)\n",
      "Gradients' difference (layer 3: 2.8133197550210223e-11)\n"
     ]
    }
   ],
   "source": [
    "for i, (grads_bprop, grads_num) in enumerate(zip(grads_all_bprop, grads_all_num)):\n",
    "    diff = np.linalg.norm(grads_bprop - grads_num) / (np.linalg.norm(grads_bprop) + np.linalg.norm(grads_num))\n",
    "    print(f\"Gradients' difference (layer {i+1}: {diff})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
